# Copyright 2018-2022 the Kubeapps contributors.
# SPDX-License-Identifier: Apache-2.0

version: 2.1
parameters:
  GOLANG_VERSION:
    type: string
    default: "1.19.0"
  NODE_VERSION:
    type: string
    default: "16.17.0"
  RUST_VERSION:
    type: string
    default: "1.63.0"
  DOCKER_VERSION:
    type: string
    default: "20.10.14"
  DOCKER_REGISTRY_VERSION:
    type: string
    default: "2.8.1"
  HELM_VERSION_MIN:
    type: "string"
    default: "v3.2.0"
  HELM_VERSION_STABLE:
    type: "string"
    default: "v3.9.4"
  OLM_VERSION:
    type: "string"
    default: "v0.22.0"
  CHARTMUSEUM_VERSION:
    type: "string"
    default: "3.9.0"
  KAPP_CONTROLLER_VERSION:
    type: "string"
    default: "v0.40.0"
  MKCERT_VERSION:
    type: "string"
    default: "v1.4.4"
  KUBECTL_VERSION:
    type: "string"
    default: "v1.24.3"
  GITHUB_VERSION:
    type: "string"
    default: "2.14.7"
  SEMVER_VERSION:
    type: "string"
    default: "3.3.0"
  KIND_VERSION:
    type: "string"
    default: "v0.15.0"
  K8S_KIND_VERSION:
    type: "string"
    default: "v1.22.13@sha256:4904eda4d6e64b402169797805b8ec01f50133960ad6c19af45173a27eadf959"
  POSTGRESQL_VERSION:
    type: "string"
    default: "14.5.0-debian-11-r6"
  GKE_STABLE_VERSION:
    type: "string"
    default: "1.21"
  GKE_REGULAR_VERSION:
    type: "string"
    default: "1.22"
  DEFAULT_MACHINE_IMG:
    type: "string"
    default: "ubuntu-2204:2022.07.1"
  IMAGES_TO_PUSH:
    type: "string"
    default: "kubeapps/apprepository-controller kubeapps/dashboard kubeapps/asset-syncer kubeapps/pinniped-proxy kubeapps/kubeapps-apis"
  CI_BOT_USERNAME:
    type: "string"
    default: "kubeapps-bot"
  CI_BOT_EMAIL:
    type: "string"
    default: "tanzu-kubeapps-team@vmware.com"
  CI_BOT_GPG:
    type: "string"
    default: "80B6EB16B1328FB18DFF2A073EBA68F3347E319D"
  CI_BOT_KUBEAPPS_KUBEAPPS_DEPLOYKEY_FINGERPRINT:
    type: "string"
    default: "20:5e:d1:68:7c:10:67:c1:ab:e2:6e:33:e3:7a:64:6e"
  CI_BOT_KUBEAPPS_KUBEAPPS_DEPLOYKEY_FILENAME:
    type: "string"
    default: "id_rsa_205ed1687c1067c1abe26e33e37a646e"
  CI_BOT_FORKED_CHARTS_DEPLOYKEY_FINGERPRINT:
    type: "string"
    default: "59:81:2a:95:a6:54:a7:46:e5:15:f5:37:b3:4f:6c:ad"
  CI_BOT_FORKED_CHARTS_DEPLOYKEY_FILENAME:
    type: "string"
    default: "id_rsa_59812a95a654a746e515f537b34f6cad"
  CHARTS_REPO_ORIGINAL:
    type: "string"
    default: "bitnami/charts"
  BRANCH_CHARTS_REPO_ORIGINAL:
    type: "string"
    default: "master"
  CHARTS_REPO_FORKED:
    type: "string"
    default: "kubeapps-bot/charts"
  BRANCH_CHARTS_REPO_FORKED:
    type: "string"
    default: "master"
  KUBEAPPS_REPO:
    type: "string"
    default: "kubeapps/kubeapps"
  BRANCH_KUBEAPPS_REPO:
    type: "string"
    default: "main"
  README_GENERATOR_REPO:
    type: "string"
    default: "bitnami-labs/readme-generator-for-helm"
  SRP_ENDPOINT:
    type: "string"
    default: "https://apigw.vmware.com/v1/s1/api/helix-beta"
  SRP_VERSION:
    type: "string"
    default: "0.2.20220825211752-571e676-57"

## Build conditions
# Build on any branch or tag
build_always: &build_always
  filters:
    tags:
      only: /^v.*/
# Build only on the main branch or in tags
build_on_main: &build_on_main
  filters:
    tags:
      only: /^v.*/
    branches:
      only: main
# Build only on tags (release)
build_on_tag: &build_on_tag
  filters:
    tags:
      only: /^v.*/
    branches:
      ignore: /.*/
# Build only on the prerelease branch or in tags (release)
build_on_tag_or_prerelease: &build_on_tag_or_prerelease
  filters:
    tags:
      only: /^v.*/
    branches:
      only: prerelease

workflows:
  version: 2
  kubeapps:
    jobs:
      - test_go:
          <<: *build_always
      - test_dashboard:
          <<: *build_always
      - test_pinniped_proxy:
          <<: *build_always
      - test_chart_render:
          <<: *build_always
      - build_go_images:
          <<: *build_always
      - build_dashboard:
          <<: *build_always
      - build_pinniped_proxy:
          <<: *build_always
      - build_e2e_runner:
          <<: *build_always
      - local_e2e_tests:
          <<: *build_always
          matrix:
            parameters:
              # Enable the line below to do bundle builds to debug CI issues
              number: ["1"]
              # number: ["1", "2", "3", "4", "5", "6", "7", "8", "9", "10"]
          requires:
            - test_go
            - test_dashboard
            - test_pinniped_proxy
            - test_chart_render
            - build_go_images
            - build_dashboard
            - build_pinniped_proxy
            - build_e2e_runner
            - sync_chart_from_bitnami
      - sync_chart_from_bitnami:
          <<: *build_on_main
      - GKE_REGULAR_VERSION_MAIN:
          <<: *build_on_tag_or_prerelease
          requires:
            - test_go
            - test_dashboard
            - test_pinniped_proxy
            - test_chart_render
            - build_go_images
            - build_dashboard
            - build_pinniped_proxy
            - build_e2e_runner
            - sync_chart_from_bitnami
      - GKE_REGULAR_VERSION_LATEST_RELEASE:
          <<: *build_on_tag_or_prerelease
          requires:
            - test_go
            - test_dashboard
            - test_pinniped_proxy
            - test_chart_render
            - build_go_images
            - build_dashboard
            - build_pinniped_proxy
            - build_e2e_runner
            - sync_chart_from_bitnami
      - GKE_STABLE_VERSION_MAIN:
          <<: *build_on_tag_or_prerelease
          requires:
            - test_go
            - test_dashboard
            - test_pinniped_proxy
            - test_chart_render
            - build_go_images
            - build_dashboard
            - build_pinniped_proxy
            - build_e2e_runner
            - sync_chart_from_bitnami
      - GKE_STABLE_VERSION_LATEST_RELEASE:
          <<: *build_on_tag_or_prerelease
          requires:
            - test_go
            - test_dashboard
            - test_pinniped_proxy
            - test_chart_render
            - build_go_images
            - build_dashboard
            - build_pinniped_proxy
            - build_e2e_runner
            - sync_chart_from_bitnami
      - push_images:
          <<: *build_on_main
          requires:
            - local_e2e_tests
      - report_srp:
          <<: *build_on_main
          requires:
            - push_images
      - sync_chart_to_bitnami:
          <<: *build_on_tag
          requires:
            - local_e2e_tests
            - GKE_REGULAR_VERSION_MAIN
            - GKE_REGULAR_VERSION_LATEST_RELEASE
            - GKE_STABLE_VERSION_MAIN
            - GKE_STABLE_VERSION_LATEST_RELEASE
      - release:
          <<: *build_on_tag
          requires:
            - sync_chart_to_bitnami
            - local_e2e_tests
            - GKE_REGULAR_VERSION_MAIN
            - GKE_REGULAR_VERSION_LATEST_RELEASE
            - GKE_STABLE_VERSION_MAIN
            - GKE_STABLE_VERSION_LATEST_RELEASE

## Definitions
common_envars: &common_envars
  DOCKER_VERSION: << pipeline.parameters.DOCKER_VERSION >>
  DOCKER_REGISTRY_VERSION: << pipeline.parameters.DOCKER_REGISTRY_VERSION >>
  GOLANG_VERSION: << pipeline.parameters.GOLANG_VERSION >>
  HELM_VERSION_MIN: << pipeline.parameters.HELM_VERSION_MIN >>
  HELM_VERSION_STABLE: << pipeline.parameters.HELM_VERSION_STABLE >>
  K8S_KIND_VERSION: << pipeline.parameters.K8S_KIND_VERSION >>
  KIND_VERSION: << pipeline.parameters.KIND_VERSION >>
  KUBECTL_VERSION: << pipeline.parameters.KUBECTL_VERSION >>
  GITHUB_VERSION: << pipeline.parameters.GITHUB_VERSION >>
  SEMVER_VERSION: << pipeline.parameters.SEMVER_VERSION >>
  MKCERT_VERSION: << pipeline.parameters.MKCERT_VERSION >>
  NODE_VERSION: << pipeline.parameters.NODE_VERSION >>
  OLM_VERSION: << pipeline.parameters.OLM_VERSION >>
  POSTGRESQL_VERSION: << pipeline.parameters.POSTGRESQL_VERSION >>
  RUST_VERSION: << pipeline.parameters.RUST_VERSION >>

common_gke_envars: &common_gke_envars
  USE_MULTICLUSTER_OIDC_ENV: "false"
  TEST_TIMEOUT_MINUTES: 6 # Timeout minutes for each test

install_gcloud_sdk: &install_gcloud_sdk
  run:
    name: "Install gcloud sdk"
    command: |
      echo "export PATH=$PATH:${HOME}/google-cloud-sdk/bin" >> $BASH_ENV
      echo "export CLOUDSDK_CORE_DISABLE_PROMPTS=1" >> $BASH_ENV
      if [ ! -d ${HOME}/google-cloud-sdk/bin ]; then
        rm -rf $HOME/google-cloud-sdk;
        curl https://sdk.cloud.google.com | bash;
      fi
install_helm_cli: &install_helm_cli
  run:
    name: "Install helm (minimum and stable)"
    command: |
      wget https://get.helm.sh/helm-${HELM_VERSION_MIN}-linux-amd64.tar.gz
      tar zxf helm-$HELM_VERSION_MIN-linux-amd64.tar.gz
      sudo mv linux-amd64/helm /usr/local/bin/

      wget https://get.helm.sh/helm-${HELM_VERSION_STABLE}-linux-amd64.tar.gz
      tar zxf helm-$HELM_VERSION_STABLE-linux-amd64.tar.gz
      sudo mv linux-amd64/helm /usr/local/bin/helm-stable
exports: &exports
  run:
    name: "Export variables"
    command: |
      # It is not possible to resolve env vars in the environment section:
      # https://circleci.com/docs/2.0/env-vars/#using-bash_env-to-set-environment-variables
      # DEV_TAG and PROD_TAG are the tags used for the Kubeapps docker images
      echo "export DEV_TAG=build-${CIRCLE_SHA1}" >> $BASH_ENV
      echo "export PROD_TAG=${CIRCLE_TAG:-latest}" >> $BASH_ENV
      # Apart from using a DEV_TAG we use a different image ID to avoid polluting the tag
      # history of the production tag
      echo "export IMG_MODIFIER=-ci" >> $BASH_ENV
build_images: &build_images
  steps:
    - setup_remote_docker:
        version: << pipeline.parameters.DOCKER_VERSION >>
    - checkout
    - <<: *exports
    - run:
        name: Build and push CI images
        command: |
          mkdir -p images/
          read -ra IMG_ARRAY \<<< "$IMAGES"
          if [[ -n "${CIRCLE_TAG}" ]]; then
            makeArgs="VERSION=${CIRCLE_TAG}"
          fi
          for IMAGE in "${IMG_ARRAY[@]}"; do
            make IMG_MODIFIER="$IMG_MODIFIER" IMAGE_TAG="${DEV_TAG}" $makeArgs kubeapps/${IMAGE}
            if [[ -n "${DOCKER_USERNAME}" && -n "${DOCKER_PASSWORD}" ]]; then
              docker login -u="${DOCKER_USERNAME}" -p="${DOCKER_PASSWORD}"
              docker push kubeapps/${IMAGE}${IMG_MODIFIER}:${DEV_TAG}
            fi
            docker save kubeapps/${IMAGE}${IMG_MODIFIER}:${DEV_TAG} > images/${IMAGE}${IMG_MODIFIER}:${DEV_TAG}
          done
    - persist_to_workspace:
        root: images
        paths:
          - "*"
install_cluster: &install_cluster
  run:
    name: "Install cluster"
    command: |
      sed -i "s/172.18.0.2/$DEFAULT_DEX_IP/g" ./site/content/docs/latest/reference/manifests/kubeapps-local-dev-apiserver-config.yaml
      {
        echo "Creating cluster..."
        kind create cluster --image kindest/node:${K8S_KIND_VERSION} --name kubeapps-ci --config=./site/content/docs/latest/reference/manifests/kubeapps-local-dev-apiserver-config.yaml --kubeconfig=${HOME}/.kube/kind-config-kubeapps-ci --retain --wait 120s &&
        kubectl --context kind-kubeapps-ci --kubeconfig ${HOME}/.kube/kind-config-kubeapps-ci apply -f ./site/content/docs/latest/reference/manifests/kubeapps-local-dev-users-rbac.yaml &&

        kubectl --context kind-kubeapps-ci --kubeconfig ${HOME}/.kube/kind-config-kubeapps-ci apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/kind/deploy.yaml &&
        sleep 5 &&
        kubectl --context kind-kubeapps-ci --kubeconfig ${HOME}/.kube/kind-config-kubeapps-ci wait --namespace ingress-nginx --for=condition=ready pod --selector=app.kubernetes.io/component=controller --timeout=120s &&

        kubectl --context kind-kubeapps-ci --kubeconfig ${HOME}/.kube/kind-config-kubeapps-ci create rolebinding kubeapps-view-secret-oidc --role view-secrets --user oidc:kubeapps-user@example.com &&
        kubectl --context kind-kubeapps-ci --kubeconfig ${HOME}/.kube/kind-config-kubeapps-ci create clusterrolebinding kubeapps-view-oidc  --clusterrole=view --user oidc:kubeapps-user@example.com &&
        echo "Cluster created"
      } || {
        echo "Cluster creation failed, retrying..."
        kind delete clusters kubeapps-ci || true
        kind create cluster --image kindest/node:${K8S_KIND_VERSION} --name kubeapps-ci --config=./site/content/docs/latest/reference/manifests/kubeapps-local-dev-apiserver-config.yaml --kubeconfig=${HOME}/.kube/kind-config-kubeapps-ci --retain --wait 120s || true &&
        kubectl --context kind-kubeapps-ci --kubeconfig ${HOME}/.kube/kind-config-kubeapps-ci apply -f ./site/content/docs/latest/reference/manifests/kubeapps-local-dev-users-rbac.yaml &&
        kubectl --context kind-kubeapps-ci --kubeconfig ${HOME}/.kube/kind-config-kubeapps-ci apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/kind/deploy.yaml &&
        sleep 5 &&
        kubectl wait --namespace ingress-nginx --for=condition=ready pod --selector=app.kubernetes.io/component=controller --timeout=120s &&

        kubectl --context kind-kubeapps-ci --kubeconfig ${HOME}/.kube/kind-config-kubeapps-ci create rolebinding kubeapps-view-secret-oidc --role view-secrets --user oidc:kubeapps-user@example.com &&
        kubectl --context kind-kubeapps-ci --kubeconfig ${HOME}/.kube/kind-config-kubeapps-ci create clusterrolebinding kubeapps-view-oidc  --clusterrole=view --user oidc:kubeapps-user@example.com &&
        echo "Cluster created"
      } || {
        echo "Error while creating the cluster after retry"
      }
export_cluster_variables: &export_cluster_variables
  run:
    name: "Export cluster variables"
    command: |
      DEX_IP=`docker network inspect kind | jq '.[0].IPAM.Config[0].Gateway' | sed  's/"//g' | awk -F. '{ print $1"."$2"."$3"."$4+1 }'`
      ADDITIONAL_CLUSTER_IP=`docker network inspect kind | jq '.[0].IPAM.Config[0].Gateway' | sed  's/"//g' | awk -F. '{ print $1"."$2"."$3"."$4+2 }'`

      echo DEFAULT_DEX_IP=$DEFAULT_DEX_IP
      echo DEX_IP=$DEX_IP
      echo ADDITIONAL_CLUSTER_IP=$ADDITIONAL_CLUSTER_IP

      # If running kubectl without args, use the default "kubeapps-ci" cluster
      cp ${HOME}/.kube/kind-config-kubeapps-ci ${HOME}/.kube/config
      kubectl config set-context kind-kubeapps-ci

      # If the default IP the proper one, the multicluster setup will fail
      if [ "$DEFAULT_DEX_IP" != "$DEX_IP" ]; then echo "Default IP does not match with current IP used in Kind"; exit 1; fi

      echo "export DEFAULT_DEX_IP=${DEFAULT_DEX_IP}" >> $BASH_ENV
      echo "export DEX_IP=${DEX_IP}" >> $BASH_ENV
      echo "export ADDITIONAL_CLUSTER_IP=${ADDITIONAL_CLUSTER_IP}" >> $BASH_ENV
install_additional_cluster: &install_additional_cluster
  run:
    name: "Install additional cluster"
    command: |
      sed -i "s/172.18.0.2/$DEFAULT_DEX_IP/g" ./site/content/docs/latest/reference/manifests/kubeapps-local-dev-additional-apiserver-config.yaml
      {
        echo "Creating additional cluster..."
        kind create cluster --image kindest/node:${K8S_KIND_VERSION} --name kubeapps-ci-additional --config=./site/content/docs/latest/reference/manifests/kubeapps-local-dev-additional-apiserver-config.yaml --kubeconfig=${HOME}/.kube/kind-config-kubeapps-ci-additional --retain --wait 120s &&
        kubectl --context kind-kubeapps-ci-additional --kubeconfig=${HOME}/.kube/kind-config-kubeapps-ci-additional apply -f ./site/content/docs/latest/reference/manifests/kubeapps-local-dev-users-rbac.yaml &&
        kubectl --context kind-kubeapps-ci-additional --kubeconfig=${HOME}/.kube/kind-config-kubeapps-ci-additional apply -f ./site/content/docs/latest/reference/manifests/kubeapps-local-dev-namespace-discovery-rbac.yaml &&

        kubectl --context kind-kubeapps-ci-additional --kubeconfig=${HOME}/.kube/kind-config-kubeapps-ci-additional create rolebinding kubeapps-view-secret-oidc --role view-secrets --user oidc:kubeapps-user@example.com &&
        kubectl --context kind-kubeapps-ci-additional --kubeconfig=${HOME}/.kube/kind-config-kubeapps-ci-additional create clusterrolebinding kubeapps-view-oidc  --clusterrole=view --user oidc:kubeapps-user@example.com &&
        echo "Additional cluster created"
      } || {
        echo "Additional cluster creation failed, retrying..."
        kind delete clusters kubeapps-ci-additional || true
        kind create cluster --image kindest/node:${K8S_KIND_VERSION} --name kubeapps-ci-additional --config=./site/content/docs/latest/reference/manifests/kubeapps-local-dev-additional-apiserver-config.yaml --kubeconfig=${HOME}/.kube/kind-config-kubeapps-ci-additional --retain --wait 120s &&
        kubectl --context kind-kubeapps-ci-additional --kubeconfig=${HOME}/.kube/kind-config-kubeapps-ci-additional apply -f ./site/content/docs/latest/reference/manifests/kubeapps-local-dev-users-rbac.yaml &&
        kubectl --context kind-kubeapps-ci-additional --kubeconfig=${HOME}/.kube/kind-config-kubeapps-ci-additional apply -f ./site/content/docs/latest/reference/manifests/kubeapps-local-dev-namespace-discovery-rbac.yaml &&

        kubectl --context kind-kubeapps-ci-additional --kubeconfig=${HOME}/.kube/kind-config-kubeapps-ci-additional create rolebinding kubeapps-view-secret-oidc --role view-secrets --user oidc:kubeapps-user@example.com &&
        kubectl --context kind-kubeapps-ci-additional --kubeconfig=${HOME}/.kube/kind-config-kubeapps-ci-additional create clusterrolebinding kubeapps-view-oidc  --clusterrole=view --user oidc:kubeapps-user@example.com &&
        echo "Additional cluster created"
      } || {
        echo "Error while creating the additional cluster after retry"
      }
load_kind_images: &load_kind_images
  run:
    name: "Load needed images into Kind"
    command:
      ./script/load-kind-image.sh docker.io/bitnami/apache:2.4.48-debian-10-r74 kubeapps-ci kubeapps-ci-additional &&
      ./script/load-kind-image.sh docker.io/bitnami/apache:2.4.48-debian-10-r75 kubeapps-ci kubeapps-ci-additional &&
      ./script/load-kind-image.sh registry:$DOCKER_REGISTRY_VERSION kubeapps-ci kubeapps-ci-additional
copy_apiserver_certificates: &copy_apiserver_certificates
  run:
    name: "Copy apiserver certificates"
    command: |
      # dex will be running on the same node as the API server in the dev environment, so we can reuse the key and cert from the apiserver
      docker cp kubeapps-ci-control-plane:/etc/kubernetes/pki/apiserver.crt ./devel/dex.crt
      docker cp kubeapps-ci-control-plane:/etc/kubernetes/pki/apiserver.key ./devel/dex.key
      sudo chown circleci ./devel/dex.key
      sudo chown circleci ./devel/dex.crt
install_kubectl: &install_kubectl
  run:
    name: "Install kubectl"
    command: |
      curl -LO https://storage.googleapis.com/kubernetes-release/release/${KUBECTL_VERSION}/bin/linux/amd64/kubectl
      chmod +x ./kubectl
      sudo mv ./kubectl /usr/local/bin/kubectl
install_kind: &install_kind
  run:
    name: "Install kind"
    command: |
      curl -LO https://github.com/kubernetes-sigs/kind/releases/download/${KIND_VERSION}/kind-Linux-amd64
      chmod +x kind-Linux-amd64
      sudo mv kind-Linux-amd64 /usr/local/bin/kind
install_mkcert: &install_mkcert
  run:
    name: "Install mkcert"
    command: |
      curl -LO "https://github.com/FiloSottile/mkcert/releases/download/${MKCERT_VERSION}/mkcert-${MKCERT_VERSION}-linux-amd64"
      chmod +x "mkcert-${MKCERT_VERSION}-linux-amd64"
      sudo mv "mkcert-${MKCERT_VERSION}-linux-amd64" /usr/local/bin/mkcert
      mkcert -install
install_github: &install_github
  run:
    # Assuming there is a personal access token created in GitHub granted with the scopes
    # "repo:status", "public_repo" and "read:org"
    # This token is passed as a GITHUB_TOKEN env var via CircleCI
    name: "Install GitHub CLI"
    command: |
      cd /tmp
      wget https://github.com/cli/cli/releases/download/v${GITHUB_VERSION}/gh_${GITHUB_VERSION}_linux_amd64.tar.gz
      tar zxf gh_${GITHUB_VERSION}_linux_amd64.tar.gz
      rm gh_${GITHUB_VERSION}_linux_amd64.tar.gz
      sudo mv gh_${GITHUB_VERSION}_linux_amd64/bin/gh /usr/local/bin/
install_semver: &install_semver
  run:
    name: "Install semver bash tool"
    command: |
      cd /tmp
      wget https://github.com/fsaintjacques/semver-tool/archive/refs/tags/${SEMVER_VERSION}.tar.gz
      tar zxf ${SEMVER_VERSION}.tar.gz
      rm ${SEMVER_VERSION}.tar.gz
      cd semver-tool-${SEMVER_VERSION}
      sudo make install
setup_gpg: &setup_gpg
  run:
    name: "Install the GPG key"
    command: |
      # Creating the files from the GPG_KEY_PUBLIC and GPG_KEY_PRIVATE env vars
      echo -e ${GPG_KEY_PUBLIC} > /tmp/public.key
      echo -e ${GPG_KEY_PRIVATE} > /tmp/private.key

      # Importing the GPG keys
      gpg --import /tmp/public.key
      gpg --import --no-tty --batch --yes /tmp/private.key

      # Trusting the imported GPG private key
      (echo 5; echo y; echo save) |  gpg --command-fd 0 --no-tty --no-greeting -q --edit-key "<< pipeline.parameters.CI_BOT_GPG >>" trust

      # Listing the key to verify the import process succeeded
      gpg --list-secret-keys << pipeline.parameters.CI_BOT_EMAIL >>

install_multicluster_deps: &install_multicluster_deps
  run:
    name: "Install multicluster deps"
    command: |
      sed -i -e "s/172.18.0.2/$DEFAULT_DEX_IP/g;s/localhost/kubeapps-ci.kubeapps/g" ./site/content/docs/latest/reference/manifests/kubeapps-local-dev-dex-values.yaml
      helm repo add dex https://charts.dexidp.io

      # Install dex
      kubectl create namespace dex
      helm install dex dex/dex --version 0.5.0 --namespace dex --values ./site/content/docs/latest/reference/manifests/kubeapps-local-dev-dex-values.yaml

      # Install openldap
      helm repo add stable https://charts.helm.sh/stable
      kubectl create namespace ldap
      helm install ldap stable/openldap --namespace ldap

      # Create certs
      kubectl -n dex create secret tls dex-web-server-tls --key ./devel/dex.key --cert ./devel/dex.crt
      mkcert -key-file ./devel/localhost-key.pem -cert-file ./devel/localhost-cert.pem localhost kubeapps-ci.kubeapps $DEFAULT_DEX_IP

run_e2e_tests: &run_e2e_tests
  run:
    name: "Run e2e tests script"
    command: |
      # If we want to test the latest version instead we override the image to be used
      if [[ -n "${TEST_LATEST_RELEASE:-}" ]]; then
        source ./script/chart_sync_utils.sh
        latest="$(latestReleaseTag)"
        DEV_TAG=${latest/v/}
        IMG_MODIFIER=""
      fi
      if ./script/e2e-test.sh $USE_MULTICLUSTER_OIDC_ENV $OLM_VERSION $DEV_TAG $IMG_MODIFIER $TEST_TIMEOUT_MINUTES $DEFAULT_DEX_IP $ADDITIONAL_CLUSTER_IP $KAPP_CONTROLLER_VERSION $CHARTMUSEUM_VERSION; then
        # Test success
        echo "export TEST_RESULT=$?" >> $BASH_ENV
      else
        # Test failed
        echo "export TEST_RESULT=$?" >> $BASH_ENV
      fi
gke_test: &gke_test
  docker:
    - image: cimg/go:<< pipeline.parameters.GOLANG_VERSION >>
      auth:
        username: $DOCKER_USERNAME
        password: $DOCKER_PASSWORD
  steps:
    - checkout
    - run:
        name: Check conditions
        command: |
          source ./script/chart_sync_utils.sh

          # In the case of GKE we will only want to build if it is
          # a build of a branch in the kubeapps repository
          if [[ -z "$GKE_ADMIN" ]]; then
            echo "Step cancelled, we are not in the Kubeapps repository"
            circleci step halt
          fi

          # Cancel job if this is a test stable release job but
          # the chart version has not been bumped
          if [[ -n "${TEST_LATEST_RELEASE:-}" ]] && ! changedVersion; then
            echo "Step cancelled, we are not releasing a new version of the chart"
            circleci step halt
          fi
    - <<: *exports
    - <<: *install_gcloud_sdk
    - setup_remote_docker:
        version: << pipeline.parameters.DOCKER_VERSION >>
    - run:
        name: Configure Google Cloud
        command: |
          gcloud -q config set project $GKE_PROJECT
          export GOOGLE_APPLICATION_CREDENTIALS=/tmp/client_secrets.json
          echo $GCLOUD_KEY > $GOOGLE_APPLICATION_CREDENTIALS
          if [ -a $GOOGLE_APPLICATION_CREDENTIALS ]; then
            gcloud -q auth activate-service-account --key-file $GOOGLE_APPLICATION_CREDENTIALS;
          fi
    - <<: *install_kubectl
    # A GKE cluster name cannot contain non-alphanumeric characters (nor uppercase letters)
    - run:
        name: Export escaped GKE cluster name
        command: |
          echo "export ESCAPED_GKE_CLUSTER=$(echo ${GKE_CLUSTER}-${CIRCLE_BRANCH:-$CIRCLE_TAG}-${TEST_LATEST_RELEASE}-${GKE_BRANCH}-ci | sed 's/[^a-z0-9-]//g')" >> $BASH_ENV
    - run:
        name: Start GKE environment
        command: |
          ./script/start-gke-env.sh $ESCAPED_GKE_CLUSTER $GKE_ZONE $GKE_BRANCH $GKE_ADMIN > /dev/null
    - <<: *install_helm_cli
    - run:
        # TODO(castelblanque) Unify shared resources with kubeapps-local-dev-users-rbac.yaml
        # that only applies to Kind clusters
        name: Apply customizations to GKE cluster
        command: |
          kubectl create namespace kubeapps-user-namespace
    - <<: *run_e2e_tests
    - store_artifacts:
        path: integration/reports
    - run: exit $TEST_RESULT
    - run:
        name: Cleanup GKE Cluster
        command: gcloud container clusters delete --async --zone $GKE_ZONE $ESCAPED_GKE_CLUSTER
        when: always
local_e2e_steps: &local_e2e_steps
  steps:
    - checkout
    - <<: *exports
    - <<: *install_kind
    - <<: *install_kubectl
    - <<: *install_cluster
    - <<: *copy_apiserver_certificates
    # Create the "kubeapps-ci-additional" cluster
    - <<: *install_additional_cluster
    # Export variables and kubeconfig
    - <<: *export_cluster_variables
    - <<: *install_mkcert
    - <<: *install_helm_cli
    - <<: *load_kind_images
    # Load images from other jobs
    - attach_workspace:
        at: /tmp/images
    - run:
        name: Load CI images in the cluster
        command: for image in /tmp/images/*; do kind load image-archive "$image" --name kubeapps-ci; done
    - <<: *install_multicluster_deps
    - <<: *run_e2e_tests
    - run:
        name: Print k8s KubeappsAPIs logs if the tests fail
        command: |
          kubectl --context kind-kubeapps-ci --kubeconfig ${HOME}/.kube/kind-config-kubeapps-ci logs -n kubeapps-ci deploy/kubeapps-internal-kubeappsapis --previous=true
        when: on_fail
    - store_artifacts:
        path: integration/reports
    - run: exit $TEST_RESULT
###

jobs:
  test_go:
    working_directory: /home/circleci/go/src/github.com/vmware-tanzu/kubeapps
    environment:
      CGO_ENABLED: "0"
      <<: *common_envars
    docker:
      - image: cimg/go:<< pipeline.parameters.GOLANG_VERSION >>
        auth:
          username: $DOCKER_USERNAME
          password: $DOCKER_PASSWORD
    steps:
      - checkout
      - <<: *exports
      - run:
          name: Run go unit tests
          command: |
            make test
      - setup_remote_docker:
          version: << pipeline.parameters.DOCKER_VERSION >>
      - run:
          name: Run go integration tests for DB
          command: |
            docker run -d --name postgresql --rm --publish 5432:5432 -e ALLOW_EMPTY_PASSWORD=yes bitnami/postgresql:${POSTGRESQL_VERSION}
            docker run --network container:postgresql -d --name tests cimg/go:${GOLANG_VERSION} tail -f /dev/null
            docker cp /home/circleci/go tests:/
            docker exec -it tests /bin/sh -c "cd /go/src/github.com/vmware-tanzu/kubeapps/ && make test-db"
  test_dashboard:
    environment:
      # Note that the max old space setting is per worker, so running the tests
      # with 4 workers on a 4Gb (free plan) needs 1Gb of max old space. Forcing
      # garbage collection to start earlier with 512M per worker.
      NODE_OPTIONS: "--max-old-space-size=512"
    docker:
      - image: cimg/node:<< pipeline.parameters.NODE_VERSION >>
        auth:
          username: $DOCKER_USERNAME
          password: $DOCKER_PASSWORD
    steps:
      - checkout
      - run:
          name: Install dashboard dependencies
          command: |
            yarn install --cwd=dashboard --frozen-lockfile
      - run:
          name: Run dashboard linter
          command: |
            yarn --cwd=dashboard run lint
      - run:
          name: Run dashboard unit tests
          command: |
            yarn --cwd=dashboard run test --maxWorkers=4 --coverage --logHeapUsage
  test_pinniped_proxy:
    docker:
      - image: cimg/rust:<< pipeline.parameters.RUST_VERSION >>
        auth:
          username: $DOCKER_USERNAME
          password: $DOCKER_PASSWORD
    steps:
      - checkout
      - run:
          name: Run rust unit tests
          command: |
            cargo test --manifest-path ./cmd/pinniped-proxy/Cargo.toml
  test_chart_render:
    environment:
      <<: *common_envars
    docker:
      - image: cimg/go:<< pipeline.parameters.GOLANG_VERSION >>
        auth:
          username: $DOCKER_USERNAME
          password: $DOCKER_PASSWORD
    steps:
      - <<: *exports
      - checkout
      - <<: *install_helm_cli
      - run:
          name: Run chart template test
          command: |
            ./script/chart-template-test.sh
  build_go_images:
    docker:
      - image: cimg/go:<< pipeline.parameters.GOLANG_VERSION >>
        auth:
          username: $DOCKER_USERNAME
          password: $DOCKER_PASSWORD
    working_directory: /home/circleci/go/src/github.com/vmware-tanzu/kubeapps
    environment:
      GOPATH: ${HOME}/.go_workspace
      IMAGES: "apprepository-controller asset-syncer kubeapps-apis"
    <<: *build_images
  build_dashboard:
    docker:
      - image: cimg/go:<< pipeline.parameters.GOLANG_VERSION >>
        auth:
          username: $DOCKER_USERNAME
          password: $DOCKER_PASSWORD
    environment:
      IMAGES: "dashboard"
    <<: *build_images
  build_pinniped_proxy:
    docker:
      # We're building the image in a docker container anyway so just re-use the golang image already in use.
      - image: cimg/go:<< pipeline.parameters.GOLANG_VERSION >>
        auth:
          username: $DOCKER_USERNAME
          password: $DOCKER_PASSWORD
    environment:
      IMAGES: "pinniped-proxy"
    <<: *build_images
  build_e2e_runner:
    docker:
      - image: cimg/go:<< pipeline.parameters.GOLANG_VERSION >>
        auth:
          username: $DOCKER_USERNAME
          password: $DOCKER_PASSWORD
    environment:
      <<: *common_envars
      IMAGE: "integration-tests"
    steps:
      - setup_remote_docker:
          version: << pipeline.parameters.DOCKER_VERSION >>
      - checkout
      - <<: *exports
      # TODO(agamez): build only if dependencies change
      # See https://github.com/vmware-tanzu/kubeapps/pull/5083
      - run:
          name: Build and push CI image
          command: |
            mkdir -p images/
            if [[ -n "${CIRCLE_TAG}" ]]; then
              makeArgs="VERSION=${CIRCLE_TAG}"
            fi
            cd integration
            make IMG_MODIFIER="$IMG_MODIFIER" IMAGE_TAG="${DEV_TAG}" $makeArgs kubeapps/${IMAGE}
            if [[ -n "${DOCKER_USERNAME}" && -n "${DOCKER_PASSWORD}" ]]; then
              docker login -u="${DOCKER_USERNAME}" -p="${DOCKER_PASSWORD}"
              docker push kubeapps/${IMAGE}${IMG_MODIFIER}:${DEV_TAG}
            fi
            docker save kubeapps/${IMAGE}${IMG_MODIFIER}:${DEV_TAG} > ../images/${IMAGE}${IMG_MODIFIER}:${DEV_TAG}
      - persist_to_workspace:
          root: images
          paths:
            - "*"
  release:
    environment:
      <<: *common_envars
    docker:
      - image: cimg/go:<< pipeline.parameters.GOLANG_VERSION >>
        auth:
          username: $DOCKER_USERNAME
          password: $DOCKER_PASSWORD
    steps:
      - checkout
      - <<: *install_github
      - run:
          # Assuming there is a personal access token created in GitHub granted with the scopes
          # "repo:status", "public_repo" and "read:org"
          # This token is passed as a GITHUB_TOKEN env var via CircleCI
          name: Run the create_release script
          command: |
            ./script/create_release.sh ${CIRCLE_TAG} << pipeline.parameters.KUBEAPPS_REPO >>
  local_e2e_tests:
    machine:
      image: << pipeline.parameters.DEFAULT_MACHINE_IMG >>
    # Reference for available machines
    # https://circleci.com/docs/2.0/configuration-reference/#machine-executor-linux
    resource_class: large
    environment:
      DEFAULT_DEX_IP: "172.18.0.2"
      TEST_UPGRADE: "1"
      USE_MULTICLUSTER_OIDC_ENV: "true"
      TEST_OPERATORS: "1"
      TEST_TIMEOUT_MINUTES: 4 # Timeout minutes for each test
      <<: *common_envars
    parameters:
      number:
        type: string
    <<: *local_e2e_steps
  GKE_REGULAR_VERSION_MAIN:
    <<: *gke_test
    environment:
      GKE_BRANCH: << pipeline.parameters.GKE_REGULAR_VERSION >>
      <<: [*common_envars, *common_gke_envars]
  GKE_REGULAR_VERSION_LATEST_RELEASE:
    <<: *gke_test
    environment:
      GKE_BRANCH: << pipeline.parameters.GKE_REGULAR_VERSION >>
      TEST_LATEST_RELEASE: 1
      <<: [*common_envars, *common_gke_envars]
  GKE_STABLE_VERSION_MAIN:
    <<: *gke_test
    environment:
      GKE_BRANCH: << pipeline.parameters.GKE_STABLE_VERSION >>
      <<: [*common_envars, *common_gke_envars]
  GKE_STABLE_VERSION_LATEST_RELEASE:
    <<: *gke_test
    environment:
      GKE_BRANCH: << pipeline.parameters.GKE_STABLE_VERSION >>
      TEST_LATEST_RELEASE: 1
      <<: [*common_envars, *common_gke_envars]
  sync_chart_to_bitnami:
    environment:
      <<: *common_envars
    docker:
      - image: cimg/node:<< pipeline.parameters.NODE_VERSION >>
        auth:
          username: $DOCKER_USERNAME
          password: $DOCKER_PASSWORD
    steps:
      - checkout
      - <<: *install_github
      - <<: *install_semver
      - <<: *setup_gpg
      - add_ssh_keys:
          fingerprints:
            # Deployment key uploaded to the kubeapps-bot/charts repository
            - << pipeline.parameters.CI_BOT_FORKED_CHARTS_DEPLOYKEY_FINGERPRINT >>

      - run:
          # This is a key pair: https://circleci.com/docs/2.0/gh-bb-integration/
          # public key uploaded to GitHub as a deploy key with write permissions in both kubeapps and kubeapps-bot/charts
          # private key uploaded to CircleCI with hostname "github.com"
          name: Start ssh-agent and configure the key
          command: |
            eval "$(ssh-agent -s)"
            # the name is always "id_rsa_"+fingerprint without ":""
            # Deployment key uploaded to the kubeapps-bot/charts repository
            ssh-add ~/.ssh/<< pipeline.parameters.CI_BOT_FORKED_CHARTS_DEPLOYKEY_FILENAME >>
      - run:
          # Assuming there is a personal access token created in GitHub granted with the scopes
          # "repo:status", "public_repo" and "read:org"
          # This token is passed as a GITHUB_TOKEN env var via CircleCI
          name: Run the chart_sync script
          command: |
            ./script/chart_sync.sh << pipeline.parameters.CI_BOT_USERNAME >> << pipeline.parameters.CI_BOT_EMAIL >> << pipeline.parameters.CI_BOT_GPG >> << pipeline.parameters.CHARTS_REPO_ORIGINAL >> << pipeline.parameters.BRANCH_CHARTS_REPO_ORIGINAL >> << pipeline.parameters.CHARTS_REPO_FORKED >> << pipeline.parameters.BRANCH_CHARTS_REPO_FORKED >>
  sync_chart_from_bitnami:
    environment:
      <<: *common_envars
    docker:
      - image: cimg/node:<< pipeline.parameters.NODE_VERSION >>
        auth:
          username: $DOCKER_USERNAME
          password: $DOCKER_PASSWORD
    steps:
      - checkout
      - <<: *install_github
      - <<: *install_semver
      - <<: *setup_gpg
      - add_ssh_keys:
          fingerprints:
            # Deployment key uploaded to the kubeapps/kubeapps repository
            - << pipeline.parameters.CI_BOT_KUBEAPPS_KUBEAPPS_DEPLOYKEY_FINGERPRINT >>
            # Deployment key uploaded to the kubeapps-bot/charts repository
            - << pipeline.parameters.CI_BOT_FORKED_CHARTS_DEPLOYKEY_FINGERPRINT >>
      - run:
          # This is a key pair: https://circleci.com/docs/2.0/gh-bb-integration/
          # public key uploaded to GitHub as a deploy key with write permissions
          # private key uploaded to CircleCI with hostname "github.com"
          name: Start ssh-agent and configure the key
          command: |
            eval "$(ssh-agent -s)"
            # the name is always "id_rsa_"+fingerprint without ":""
            # Deployment key uploaded to the kubeapps/kubeapps repository
            ssh-add ~/.ssh/<< pipeline.parameters.CI_BOT_KUBEAPPS_KUBEAPPS_DEPLOYKEY_FILENAME >>
            # Deployment key uploaded to the kubeapps-bot/charts repository
            ssh-add ~/.ssh/<< pipeline.parameters.CI_BOT_FORKED_CHARTS_DEPLOYKEY_FILENAME >>
      - run:
          # Assuming there is a personal access token created in GitHub granted with the scopes
          # "repo:status", "public_repo" and "read:org"
          # This token is passed as a GITHUB_TOKEN env var via CircleCI
          name: Run the check_upstream_chart script
          command: |
            ./script/chart_upstream_checker.sh << pipeline.parameters.CI_BOT_USERNAME >> << pipeline.parameters.CI_BOT_EMAIL >> << pipeline.parameters.CI_BOT_GPG >> << pipeline.parameters.CI_BOT_FORKED_CHARTS_DEPLOYKEY_FILENAME >> << pipeline.parameters.CHARTS_REPO_ORIGINAL >> << pipeline.parameters.BRANCH_CHARTS_REPO_ORIGINAL >> << pipeline.parameters.CHARTS_REPO_FORKED >> << pipeline.parameters.BRANCH_CHARTS_REPO_FORKED >> << pipeline.parameters.KUBEAPPS_REPO >> << pipeline.parameters.BRANCH_KUBEAPPS_REPO >> << pipeline.parameters.README_GENERATOR_REPO >>
  report_srp:
    environment:
      <<: *common_envars
    docker:
      - image: cimg/go:<< pipeline.parameters.GOLANG_VERSION >>
        auth:
          username: $DOCKER_USERNAME
          password: $DOCKER_PASSWORD
    steps:
      - checkout
      - run:
          name: Init submodules
          command: |
            git submodule update --init --recursive
      - run:
          name: Install and configure the SRP tool
          command: |
            wget https://vmwaresaas.jfrog.io/artifactory/srp-tools/srpcli/<< pipeline.parameters.SRP_VERSION >>/linux/srp
            sudo chmod +x srp
            sudo mv ./srp /usr/local/bin/
            srp --version
            srp config --srp-endpoint << pipeline.parameters.SRP_ENDPOINT >>
            srp config auth --client-id $KUBEAPPS_SRP_CLIENT_ID --client-secret $KUBEAPPS_SRP_CLIENT_SECRET
      # - run:
      #     name: Install and configure the SRP observer tool
      #     command: |
      #       wget https://s3.amazonaws.com/srp-cli/linux-observer-latest.tar.gz
      #       tar zxf linux-observer-latest.tar.gz
      - run:
          name: Generate the "source provenance" file
          command: |
            # This UID should have been already set in the internal tool.
            PROV_OBJ_UID="uid.obj.build.circleci(instance='circleci.com',type='<< pipeline.project.type >>',namespace='${CIRCLE_PROJECT_USERNAME}/${CIRCLE_PROJECT_REPONAME}',branch='${CIRCLE_BRANCH}',commit_id='${CIRCLE_SHA1}',build_id='<< pipeline.number >>/${CIRCLE_WORKFLOW_ID}/${CIRCLE_BUILD_NUM}')"
            echo "PROV_OBJ_UID=${PROV_OBJ_UID}"
            # Using CIRCLE_TAG as the version if defined (i.e., when releasing a version); use the commit SHA otherwise.
            VERSION=$([ -z "${CIRCLE_TAG}" ] && echo "${CIRCLE_SHA1}" || echo "${CIRCLE_TAG}")
            srp provenance source --verbose --scm-type git --name "kubeapps" --path ./ --saveto ./source-provenance.json --comp-uid "${PROV_OBJ_UID}" --build-number "${CIRCLE_WORKFLOW_ID}" --version "${VERSION}" --all-ephemeral true --build-type release
            cat ./source-provenance.json
      - store_artifacts:
          path: source-provenance.json
      # TODO(agamez): we will need to create the "network provenance" file soon.
      # - run:
      #     name: Generate the "network provenance" file
      #     command: |
      #       JAVA_HOME="/dev/null"
      #       mkdir provenance-go
      #       ./bin/observer_agent -t -o ./provenance-go -- go mod download -x
      #       cat provenance-go/provenance.json
      #       mkdir provenance-yarn
      #       ./bin/observer_agent -t -o ./provenance-yarn -- yarn install --cwd=dashboard --frozen-lockfile
      #       cat provenance-yarn/provenance.json
      #       jq -s 'flatten | group_by(.artifact_repositories) | map(reduce .[] as $x ({}; . * $x))'  provenance-go/provenance.json  provenance-yarn/provenance.json > network-provenance.json
      #       cat network-provenance.json
      # - store_artifacts:
      #     path: network-provenance.json
      # - run:
      #     name: Merge the provenance files
      #     command: |
      #       srp provenance merge --verbose --source ./source-provenance.json --network ./network-provenance.json --saveto ./merged-provenance.json
      # - store_artifacts:
      #     path: merged-provenance.json
      - run:
          name: Validate and submit the provenance files to the SRP Metadata service
          command: |
            srp uid validate "uid.mtd.provenance_2_5.fragment(obj_uid=uid.obj.build.circleci(instance='circleci.com',type='<< pipeline.project.type >>',namespace='${CIRCLE_PROJECT_USERNAME}/${CIRCLE_PROJECT_REPONAME}',branch='${CIRCLE_BRANCH}',commit_id='${CIRCLE_SHA1}',build_id='<< pipeline.number >>/${CIRCLE_WORKFLOW_ID}/${CIRCLE_BUILD_NUM}'),revision='')"
            srp metadata submit --verbose --path ./source-provenance.json
  push_images:
    docker:
      - image: cimg/go:<< pipeline.parameters.GOLANG_VERSION >>
        auth:
          username: $DOCKER_USERNAME
          password: $DOCKER_PASSWORD
    steps:
      - setup_remote_docker:
          version: << pipeline.parameters.DOCKER_VERSION >>
      - <<: *exports
      - run:
          name: Push images
          command: |
            if [[ -z "$CIRCLE_PULL_REQUEST" && -n "$DOCKER_USERNAME" && -n "$DOCKER_PASSWORD" ]]; then
              docker login -u="${DOCKER_USERNAME}" -p="${DOCKER_PASSWORD}"
              for IMAGE in << pipeline.parameters.IMAGES_TO_PUSH >>; do
                docker pull ${IMAGE}${IMG_MODIFIER}:${DEV_TAG}
                docker tag ${IMAGE}${IMG_MODIFIER}:${DEV_TAG} ${IMAGE}:${PROD_TAG}
                docker push ${IMAGE}:${PROD_TAG}
              done
            fi
