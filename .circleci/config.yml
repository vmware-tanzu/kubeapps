version: 2.1
parameters:
  GOLANG_VERSION:
    type: string
    default: "1.17.1"
  NODE_VERSION:
    type: string
    default: "14"
  RUST_VERSION:
    type: string
    default: "1.55.0"
  DOCKER_VERSION:
    type: string
    default: "20.10.7"
  HELM_VERSION_MIN:
    type: "string"
    default: "v3.1.0"
  HELM_VERSION_STABLE:
    type: "string"
    default: "v3.7.0"
  OLM_VERSION:
    type: "string"
    default: "v0.18.3"
  MKCERT_VERSION:
    type: "string"
    default: "v1.4.3"
  KUBECTL_VERSION:
    type: "string"
    default: "v1.22.2"
  KIND_VERSION:
    type: "string"
    default: "v0.11.1"
  K8S_KIND_VERSION:
    type: "string"
    default: "v1.21.1@sha256:69860bda5563ac81e3c0057d654b5253219618a22ec3a346306239bba8cfa1a6"
  POSTGRESQL_VERSION:
    type: "string"
    default: "11.13.0-debian-10-r39"
  IMAGES_TO_PUSH:
    type: "string"
    default: "coreweave/apprepository-controller coreweave/dashboard coreweave/asset-syncer coreweave/assetsvc coreweave/kubeops coreweave/pinniped-proxy coreweave/kubeapps-apis"

## Build conditions
# Build in any branch or tag
build_always: &build_always
  filters:
    tags:
      only: /^v.*/
# Build only in master or in tags
build_on_master: &build_on_master
  filters:
    tags:
      only: /^v.*/
    branches:
      only: master
# Build only in tags (release)
build_on_tag: &build_on_tag
  filters:
    tags:
      only: /^v.*/
    branches:
      ignore: /.*/

workflows:
  version: 2
  kubeapps:
    jobs:
      - test_go:
          <<: *build_always
      - test_dashboard:
          <<: *build_always
      - test_pinniped_proxy:
          <<: *build_always
      - test_chart_render:
          <<: *build_always
      - build_go_images:
          <<: *build_always
      - build_dashboard:
          <<: *build_always
      - build_pinniped_proxy:
          <<: *build_always
      - local_e2e_tests:
          <<: *build_always
          matrix:
            parameters:
              # Enable the line below to do bundle builds to debug CI issues
              number: ["1"]
              # number: ["1", "2", "3", "4", "5", "6", "7", "8", "9", "10"]
          requires:
            - test_go
            - test_dashboard
            - test_pinniped_proxy
            - test_chart_render
            - build_go_images
            - build_dashboard
            - build_pinniped_proxy
      - push_images:
          <<: *build_always
          requires:
            - local_e2e_tests
      - release:
          <<: *build_always
          requires:
            - local_e2e_tests

## Definitions
common_envars: &common_envars
  DOCKER_VERSION: << pipeline.parameters.DOCKER_VERSION >>
  GOLANG_VERSION: << pipeline.parameters.GOLANG_VERSION >>
  HELM_VERSION_MIN: << pipeline.parameters.HELM_VERSION_MIN >>
  HELM_VERSION_STABLE: << pipeline.parameters.HELM_VERSION_STABLE >>
  K8S_KIND_VERSION: << pipeline.parameters.K8S_KIND_VERSION >>
  KIND_VERSION: << pipeline.parameters.KIND_VERSION >>
  KUBECTL_VERSION: << pipeline.parameters.KUBECTL_VERSION >>
  MKCERT_VERSION: << pipeline.parameters.MKCERT_VERSION >>
  NODE_VERSION: << pipeline.parameters.NODE_VERSION >>
  OLM_VERSION: << pipeline.parameters.OLM_VERSION >>
  POSTGRESQL_VERSION: << pipeline.parameters.POSTGRESQL_VERSION >>
  RUST_VERSION: << pipeline.parameters.RUST_VERSION >>

install_helm_cli: &install_helm_cli
  run:
    name: "Install helm (minimum and stable)"
    command: |
      wget https://get.helm.sh/helm-${HELM_VERSION_MIN}-linux-amd64.tar.gz
      tar zxf helm-$HELM_VERSION_MIN-linux-amd64.tar.gz
      sudo mv linux-amd64/helm /usr/local/bin/

      wget https://get.helm.sh/helm-${HELM_VERSION_STABLE}-linux-amd64.tar.gz
      tar zxf helm-$HELM_VERSION_STABLE-linux-amd64.tar.gz
      sudo mv linux-amd64/helm /usr/local/bin/helm-stable
exports: &exports
  run:
    name: "Export variables"
    command: |
      # It is not possible to resolve env vars in the environment section:
      # https://circleci.com/docs/2.0/env-vars/#using-bash_env-to-set-environment-variables
      # DEV_TAG and PROD_TAG are the tags used for the Kubeapps docker images
      echo "export DEV_TAG=build-${CIRCLE_SHA1}" >> $BASH_ENV
      echo "export PROD_TAG=${CIRCLE_TAG:-latest}" >> $BASH_ENV
      # Apart from using a DEV_TAG we use a different image ID to avoid polluting the tag
      # history of the production tag
      echo "export IMG_MODIFIER=-ci" >> $BASH_ENV
build_images: &build_images
  steps:
    - setup_remote_docker:
        version: << pipeline.parameters.DOCKER_VERSION >>
    - checkout
    - <<: *exports
    - run:
        name: Build and push CI images
        command: |
          mkdir -p images/
          read -ra IMG_ARRAY \<<< "$IMAGES"
          if [[ -n "${CIRCLE_TAG}" ]]; then
            makeArgs="VERSION=${CIRCLE_TAG}"
          fi
          for IMAGE in "${IMG_ARRAY[@]}"; do
            make IMG_MODIFIER="$IMG_MODIFIER" IMAGE_TAG="${DEV_TAG}" $makeArgs coreweave/${IMAGE}
            if [[ -n "${DOCKER_USERNAME}" && -n "${DOCKER_PASSWORD}" ]]; then
              docker login -u="${DOCKER_USERNAME}" -p="${DOCKER_PASSWORD}"
              docker push coreweave/${IMAGE}${IMG_MODIFIER}:${DEV_TAG}
            fi
            docker save coreweave/${IMAGE}${IMG_MODIFIER}:${DEV_TAG} > images/${IMAGE}${IMG_MODIFIER}:${DEV_TAG}
          done
    - persist_to_workspace:
        root: images
        paths:
          - "*"
install_cluster: &install_cluster
  run:
    name: "Install cluster"
    command: |
      sed -i "s/172.18.0.2/$DEFAULT_DEX_IP/g" ./docs/user/manifests/kubeapps-local-dev-apiserver-config.yaml
      {
        echo "Creating cluster..."
        kind create cluster --image kindest/node:${K8S_KIND_VERSION} --name kubeapps-ci --config=./docs/user/manifests/kubeapps-local-dev-apiserver-config.yaml --kubeconfig=${HOME}/.kube/kind-config-kubeapps-ci --retain --wait 120s &&
        kubectl --context kind-kubeapps-ci --kubeconfig ${HOME}/.kube/kind-config-kubeapps-ci apply -f ./docs/user/manifests/kubeapps-local-dev-users-rbac.yaml &&

        kubectl --context kind-kubeapps-ci --kubeconfig ${HOME}/.kube/kind-config-kubeapps-ci apply -f ./docs/user/manifests/ingress-nginx-kind-with-large-proxy-buffers.yaml &&
        sleep 5 &&
        kubectl --context kind-kubeapps-ci --kubeconfig ${HOME}/.kube/kind-config-kubeapps-ci wait --namespace ingress-nginx --for=condition=ready pod --selector=app.kubernetes.io/component=controller --timeout=120s &&

        kubectl --context kind-kubeapps-ci --kubeconfig ${HOME}/.kube/kind-config-kubeapps-ci delete rolebinding kubeapps-user -n  kubeapps-user-namespace &&
        kubectl --context kind-kubeapps-ci --kubeconfig ${HOME}/.kube/kind-config-kubeapps-ci create rolebinding kubeapps-view-secret-oidc --role view-secrets --user oidc:kubeapps-user@example.com &&
        kubectl --context kind-kubeapps-ci --kubeconfig ${HOME}/.kube/kind-config-kubeapps-ci create clusterrolebinding kubeapps-view-oidc  --clusterrole=view --user oidc:kubeapps-user@example.com &&
        echo "Cluster created"
      } || {
        echo "Cluster creation failed, retrying..."
        kind delete clusters kubeapps-ci || true
        kind create cluster --image kindest/node:${K8S_KIND_VERSION} --name kubeapps-ci --config=./docs/user/manifests/kubeapps-local-dev-apiserver-config.yaml --kubeconfig=${HOME}/.kube/kind-config-kubeapps-ci --retain --wait 120s || true &&
        kubectl --context kind-kubeapps-ci --kubeconfig ${HOME}/.kube/kind-config-kubeapps-ci apply -f ./docs/user/manifests/kubeapps-local-dev-users-rbac.yaml &&
        kubectl --context kind-kubeapps-ci --kubeconfig ${HOME}/.kube/kind-config-kubeapps-ci apply -f ./docs/user/manifests/ingress-nginx-kind-with-large-proxy-buffers.yaml &&
        sleep 5 &&
        kubectl wait --namespace ingress-nginx --for=condition=ready pod --selector=app.kubernetes.io/component=controller --timeout=120s &&

        kubectl --context kind-kubeapps-ci --kubeconfig ${HOME}/.kube/kind-config-kubeapps-ci delete rolebinding kubeapps-user -n  kubeapps-user-namespace &&
        kubectl --context kind-kubeapps-ci --kubeconfig ${HOME}/.kube/kind-config-kubeapps-ci create rolebinding kubeapps-view-secret-oidc --role view-secrets --user oidc:kubeapps-user@example.com &&
        kubectl --context kind-kubeapps-ci --kubeconfig ${HOME}/.kube/kind-config-kubeapps-ci create clusterrolebinding kubeapps-view-oidc  --clusterrole=view --user oidc:kubeapps-user@example.com &&
        echo "Cluster created"
      } || {
        echo "Error while creating the cluster after retry"
      }
export_cluster_variables: &export_cluster_variables
  run:
    name: "Export cluster variables"
    command: |
      DEX_IP=`docker network inspect kind | jq '.[0].IPAM.Config[0].Gateway' | sed  's/"//g' | awk -F. '{ print $1"."$2"."$3"."$4+1 }'`
      ADDITIONAL_CLUSTER_IP=`docker network inspect kind | jq '.[0].IPAM.Config[0].Gateway' | sed  's/"//g' | awk -F. '{ print $1"."$2"."$3"."$4+2 }'`

      echo DEFAULT_DEX_IP=$DEFAULT_DEX_IP
      echo DEX_IP=$DEX_IP
      echo ADDITIONAL_CLUSTER_IP=$ADDITIONAL_CLUSTER_IP

      # If running kubectl without args, use the default "kubeapps-ci" cluster
      cp ${HOME}/.kube/kind-config-kubeapps-ci ${HOME}/.kube/config
      kubectl config set-context kind-kubeapps-ci

      # If the default IP the proper one, the multicluster setup will fail
      if [ "$DEFAULT_DEX_IP" != "$DEX_IP" ]; then echo "Default IP does not match with current IP used in Kind"; exit 1; fi

      echo "export DEFAULT_DEX_IP=${DEFAULT_DEX_IP}" >> $BASH_ENV
      echo "export DEX_IP=${DEX_IP}" >> $BASH_ENV
      echo "export ADDITIONAL_CLUSTER_IP=${ADDITIONAL_CLUSTER_IP}" >> $BASH_ENV
install_additional_cluster: &install_additional_cluster
  run:
    name: "Install additional cluster"
    command: |
      sed -i "s/172.18.0.2/$DEFAULT_DEX_IP/g" ./docs/user/manifests/kubeapps-local-dev-additional-apiserver-config.yaml
      {
        echo "Creating additional cluster..."
        kind create cluster --image kindest/node:${K8S_KIND_VERSION} --name kubeapps-ci-additional --config=./docs/user/manifests/kubeapps-local-dev-additional-apiserver-config.yaml --kubeconfig=${HOME}/.kube/kind-config-kubeapps-ci-additional --retain --wait 120s &&
        kubectl --context kind-kubeapps-ci-additional --kubeconfig ${HOME}/.kube/kind-config-kubeapps-ci-additional apply --kubeconfig=${HOME}/.kube/kind-config-kubeapps-ci-additional -f ./docs/user/manifests/kubeapps-local-dev-users-rbac.yaml &&
        kubectl --context kind-kubeapps-ci-additional --kubeconfig ${HOME}/.kube/kind-config-kubeapps-ci-additional apply --kubeconfig=${HOME}/.kube/kind-config-kubeapps-ci-additional -f ./docs/user/manifests/kubeapps-local-dev-namespace-discovery-rbac.yaml &&

        kubectl --context kind-kubeapps-ci-additional --kubeconfig ${HOME}/.kube/kind-config-kubeapps-ci-additional delete rolebinding kubeapps-user -n  kubeapps-user-namespace &&
        kubectl --context kind-kubeapps-ci-additional --kubeconfig ${HOME}/.kube/kind-config-kubeapps-ci-additional create rolebinding kubeapps-view-secret-oidc --role view-secrets --user oidc:kubeapps-user@example.com &&
        kubectl --context kind-kubeapps-ci-additional --kubeconfig ${HOME}/.kube/kind-config-kubeapps-ci-additional create clusterrolebinding kubeapps-view-oidc  --clusterrole=view --user oidc:kubeapps-user@example.com &&
        echo "Additional cluster created"
      } || {
        echo "Additional cluster creation failed, retrying..."
        kind delete clusters kubeapps-ci-additional || true
        kind create cluster --image kindest/node:${K8S_KIND_VERSION} --name kubeapps-ci-additional --config=./docs/user/manifests/kubeapps-local-dev-additional-apiserver-config.yaml --kubeconfig=${HOME}/.kube/kind-config-kubeapps-ci-additional --retain --wait 120s &&
        kubectl --context kind-kubeapps-ci-additional --kubeconfig ${HOME}/.kube/kind-config-kubeapps-ci-additional apply --kubeconfig=${HOME}/.kube/kind-config-kubeapps-ci-additional -f ./docs/user/manifests/kubeapps-local-dev-users-rbac.yaml &&
        kubectl --context kind-kubeapps-ci-additional --kubeconfig ${HOME}/.kube/kind-config-kubeapps-ci-additional apply --kubeconfig=${HOME}/.kube/kind-config-kubeapps-ci-additional -f ./docs/user/manifests/kubeapps-local-dev-namespace-discovery-rbac.yaml &&

        kubectl --context kind-kubeapps-ci-additional --kubeconfig ${HOME}/.kube/kind-config-kubeapps-ci-additional delete rolebinding kubeapps-user -n  kubeapps-user-namespace &&
        kubectl --context kind-kubeapps-ci-additional --kubeconfig ${HOME}/.kube/kind-config-kubeapps-ci-additional create rolebinding kubeapps-view-secret-oidc --role view-secrets --user oidc:kubeapps-user@example.com &&
        kubectl --context kind-kubeapps-ci-additional --kubeconfig ${HOME}/.kube/kind-config-kubeapps-ci-additional create clusterrolebinding kubeapps-view-oidc  --clusterrole=view --user oidc:kubeapps-user@example.com &&
        echo "Additional cluster created"
      } || {
        echo "Error while creating the additional cluster after retry"
      }

copy_apiserver_certificates: &copy_apiserver_certificates
  run:
    name: "Copy apiserver certificates"
    command: |
      # dex will be running on the same node as the API server in the dev environment, so we can reuse the key and cert from the apiserver
      docker cp kubeapps-ci-control-plane:/etc/kubernetes/pki/apiserver.crt ./devel/dex.crt
      docker cp kubeapps-ci-control-plane:/etc/kubernetes/pki/apiserver.key ./devel/dex.key
      sudo chown circleci ./devel/dex.key
      sudo chown circleci ./devel/dex.crt
install_kubectl: &install_kubectl
  run:
    name: "Install kubectl"
    command: |
      curl -LO https://storage.googleapis.com/kubernetes-release/release/${KUBECTL_VERSION}/bin/linux/amd64/kubectl
      chmod +x ./kubectl
      sudo mv ./kubectl /usr/local/bin/kubectl
install_kind: &install_kind
  run:
    name: "Install kind"
    command: |
      curl -LO https://github.com/kubernetes-sigs/kind/releases/download/${KIND_VERSION}/kind-Linux-amd64
      chmod +x kind-Linux-amd64
      sudo mv kind-Linux-amd64 /usr/local/bin/kind
install_mkcert: &install_mkcert
  run:
    name: "Install mkcert"
    command: |
      curl -LO "https://github.com/FiloSottile/mkcert/releases/download/${MKCERT_VERSION}/mkcert-${MKCERT_VERSION}-linux-amd64"
      chmod +x "mkcert-${MKCERT_VERSION}-linux-amd64"
      sudo mv "mkcert-${MKCERT_VERSION}-linux-amd64" /usr/local/bin/mkcert
      mkcert -install

install_multicluster_deps: &install_multicluster_deps
  run:
    name: "Install multicluster deps"
    command: |
      sed -i -e "s/172.18.0.2/$DEFAULT_DEX_IP/g;s/localhost/kubeapps-ci.kubeapps/g" ./docs/user/manifests/kubeapps-local-dev-dex-values.yaml
      helm repo add dex https://charts.dexidp.io

      # Install dex
      kubectl create namespace dex
      helm install dex dex/dex --version 0.5.0 --namespace dex --values ./docs/user/manifests/kubeapps-local-dev-dex-values.yaml

      # Install openldap
      helm repo add stable https://charts.helm.sh/stable
      kubectl create namespace ldap
      helm install ldap stable/openldap --namespace ldap

      # Create certs
      kubectl -n dex create secret tls dex-web-server-tls --key ./devel/dex.key --cert ./devel/dex.crt
      mkcert -key-file ./devel/localhost-key.pem -cert-file ./devel/localhost-cert.pem localhost kubeapps-ci.kubeapps $DEFAULT_DEX_IP

run_e2e_tests: &run_e2e_tests
  run:
    name: "Run e2e tests script"
    command: |
      # If we want to test the latest version instead we override the image to be used
      if [[ -n "$TEST_LATEST_RELEASE" ]]; then
        source ./script/chart_sync_utils.sh
        latest="$(latestReleaseTag)"
        DEV_TAG=${latest/v/}
        IMG_MODIFIER=""
      fi
      if ./script/e2e-test.sh $USE_MULTICLUSTER_OIDC_ENV $OLM_VERSION $DEV_TAG $IMG_MODIFIER $DEFAULT_DEX_IP $ADDITIONAL_CLUSTER_IP; then
        # Test success
        echo "export TEST_RESULT=$?" >> $BASH_ENV
      else
        # Test failed
        echo "export TEST_RESULT=$?" >> $BASH_ENV
      fi
local_e2e_steps: &local_e2e_steps
  steps:
    - checkout
    - <<: *exports
    - <<: *install_kind
    - <<: *install_kubectl
    - <<: *install_cluster
    - <<: *copy_apiserver_certificates
    # Create the "kubeapps-ci-additional" cluster
    - <<: *install_additional_cluster
    # Export variables and kubeconfig
    - <<: *export_cluster_variables
    - <<: *install_mkcert
    - <<: *install_helm_cli
    # Load images from other jobs
    - attach_workspace:
        at: /tmp/images
    - run:
        name: Load CI images in the cluster
        command: for image in /tmp/images/*; do kind load image-archive "$image" --name kubeapps-ci; done
    - <<: *install_multicluster_deps
    - <<: *run_e2e_tests
    - store_artifacts:
        path: integration/reports
    - run: exit $TEST_RESULT
###

jobs:
  test_go:
    working_directory: /go/src/github.com/coreweave/kubeapps
    environment:
      CGO_ENABLED: "0"
      <<: *common_envars
    docker:
      - image: circleci/golang:<< pipeline.parameters.GOLANG_VERSION >>
    steps:
      - checkout
      - <<: *exports
      - run:
          name: Run go unit tests
          command: |
            make test
      - setup_remote_docker
      - run:
          name: Run go integration tests for DB
          command: |
            docker run -d --name postgresql --rm --publish 5432:5432 -e ALLOW_EMPTY_PASSWORD=yes bitnami/postgresql:${POSTGRESQL_VERSION}
            docker run --network container:postgresql -d --name tests circleci/golang:${GOLANG_VERSION} tail -f /dev/null
            docker cp /go tests:/
            docker exec -it tests /bin/sh -c "cd /go/src/github.com/coreweave/kubeapps/ && make test-db"
  test_dashboard:
    docker:
      - image: circleci/node:<< pipeline.parameters.NODE_VERSION >>
    steps:
      - checkout
      - run:
          name: Install dashboard dependencies
          command: |
            yarn install --cwd=dashboard --frozen-lockfile
      - run:
          name: Run dashboard linter
          command: |
            yarn --cwd=dashboard run lint
      - run:
          name: Run dashboard unit tests
          command: |
            yarn --cwd=dashboard run test --maxWorkers=4 --coverage
  test_pinniped_proxy:
    docker:
      - image: circleci/rust:<< pipeline.parameters.RUST_VERSION >>
    steps:
      - checkout
      - run:
          name: Run rust unit tests
          command: |
            cargo test --manifest-path ./cmd/pinniped-proxy/Cargo.toml
  test_chart_render:
    environment:
      <<: *common_envars
    docker:
      - image: circleci/golang:<< pipeline.parameters.GOLANG_VERSION >>
    steps:
      - <<: *exports
      - checkout
      - <<: *install_helm_cli
      - run:
          name: Run chart template test
          command: |
            ./script/chart-template-test.sh
  build_go_images:
    docker:
      - image: circleci/golang:<< pipeline.parameters.GOLANG_VERSION >>
    working_directory: /go/src/github.com/coreweave/kubeapps
    environment:
      GOPATH: ${HOME}/.go_workspace
      IMAGES: "kubeops apprepository-controller asset-syncer assetsvc kubeapps-apis"
    <<: *build_images
  build_dashboard:
    docker:
      - image: circleci/golang:<< pipeline.parameters.GOLANG_VERSION >>
    environment:
      IMAGES: "dashboard"
    <<: *build_images
  build_pinniped_proxy:
    docker:
      # We're building the image in a docker container anyway so just re-use the golang image already in use.
      - image: circleci/golang:<< pipeline.parameters.GOLANG_VERSION >>
    environment:
      IMAGES: "pinniped-proxy"
    <<: *build_images
  release:
    docker:
      - image: circleci/golang:<< pipeline.parameters.GOLANG_VERSION >>
    steps:
      - checkout
      - run:
          name: Create release
          command: |
            REPO_DOMAIN=kubeapps REPO_NAME=kubeapps ./script/create_release.sh ${CIRCLE_TAG}
  local_e2e_tests:
    machine: true
    environment:
      DEFAULT_DEX_IP: "172.18.0.2"
      KUBEAPPS_DB: "postgresql"
      TEST_UPGRADE: "1"
      USE_MULTICLUSTER_OIDC_ENV: "true"
      <<: *common_envars
    parameters:
      number:
        type: string
    <<: *local_e2e_steps
  push_images:
    docker:
      - image: circleci/golang:<< pipeline.parameters.GOLANG_VERSION >>
    steps:
      - setup_remote_docker
      - <<: *exports
      - run:
          name: Push images
          command: |
            if [[ -z "$CIRCLE_PULL_REQUEST" && -n "$DOCKER_USERNAME" && -n "$DOCKER_PASSWORD" ]]; then
              docker login -u="${DOCKER_USERNAME}" -p="${DOCKER_PASSWORD}"
              for IMAGE in << pipeline.parameters.IMAGES_TO_PUSH >>; do
                docker pull ${IMAGE}${IMG_MODIFIER}:${DEV_TAG}
                docker tag ${IMAGE}${IMG_MODIFIER}:${DEV_TAG} ${IMAGE}:${PROD_TAG}
                docker push ${IMAGE}:${PROD_TAG}
              done
            fi
